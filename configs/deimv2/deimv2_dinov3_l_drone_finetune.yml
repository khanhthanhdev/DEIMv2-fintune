__include__: [
  '../dataset/drone_detection.yml',
  '../runtime.yml',
  '../base/dataloader.yml',
  '../base/optimizer.yml',
  '../base/deimv2.yml',
]


output_dir: ./outputs/deimv2_dinov3_l_drone_finetune

# Load pretrained weights for fine-tuning
resume: https://huggingface.co/Intellindust/DEIMv2_DINOv3_L_COCO/resolve/main/pytorch_model.bin

DEIM:
  backbone: DINOv3STAs

DINOv3STAs:
  name: dinov3_vits16
  weights_path: ./ckpts/dinov3_vits16_pretrain_lvd1689m-08c60483.pth
  interaction_indexes: [5,8,11]   # only need the [1/8, 1/16, 1/32]
  finetune: True
  conv_inplane: 32
  hidden_dim: 224

HybridEncoder:
  in_channels: [224, 224, 224]
  hidden_dim: 224
  dim_feedforward: 896

DEIMTransformer:
  feat_channels: [224, 224, 224]
  hidden_dim: 224
  num_layers: 4
  eval_idx: -1
  dim_feedforward: 1792

## Fine-tuning parameters (reduced epochs and learning rates)
epoches: 24  # Reduced for fine-tuning

lrsheduler: flatcosine
lr_gamma: 0.5
warmup_iter: 500  # Reduced warmup for fine-tuning
flat_epoch: 12    # Adjusted for shorter training
no_aug_epoch: 4   # Reduced no-augmentation epochs

## Fine-tuning Optimizer (lower learning rates)
optimizer:
  type: AdamW
  params:
    -
      # except norm/bn/bias in self.dinov3 - lower LR for backbone
      params: '^(?=.*.dinov3)(?!.*(?:norm|bn|bias)).*$'
      lr: 0.00000625  # Reduced by factor of 2
    -
      # including norm/bn/bias in self.dinov3 - lower LR for backbone
      params: '^(?=.*.dinov3)(?=.*(?:norm|bn|bias)).*$'
      lr: 0.00000625  # Reduced by factor of 2
      weight_decay: 0.
    -
      # including norm/bn/bias except for the self.dinov3 - normal LR for decoder
      params: '^(?=.*(?:sta|encoder|decoder))(?=.*(?:norm|bn|bias)).*$'
      weight_decay: 0.

  lr: 0.00025  # Reduced base LR by factor of 2
  betas: [0.9, 0.999]
  weight_decay: 0.000125


## Dense O2O: Mosaic + Mixup + CopyBlend (lighter augmentation for fine-tuning)
train_dataloader:
  dataset:
    transforms:
      ops:
        - {type: Mosaic, output_size: 320, rotation_range: 10, translation_range: [0.1, 0.1], scaling_range: [0.5, 1.5],
           probability: 0.8, fill_value: 0, use_cache: True, max_cached_images: 50, random_pop: True}  # Reduced probability
        - {type: RandomPhotometricDistort, p: 0.3}  # Reduced probability
        - {type: RandomZoomOut, fill: 0}
        - {type: RandomIoUCrop, p: 0.6}  # Reduced probability
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: RandomHorizontalFlip}
        - {type: Resize, size: [640, 640], }
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: Normalize, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: True}
      policy:
        epoch: [2, 12, 20]   # Adjusted for shorter training

  collate_fn:
    mixup_epochs: [2, 12]  # Adjusted epochs
    stop_epoch: 20         # Adjusted stop epoch
    copyblend_epochs: [2, 20]
    base_size_repeat: 3

val_dataloader:
  dataset:
    transforms:
      ops:
        - {type: Resize, size: [640, 640], }
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: Normalize, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}

## DEIM Loss (adjusted for single class)
DEIMCriterion:
  matcher:
    matcher_change_epoch: 18  # Adjusted for shorter training